{
  "ch1": [
    "You've been talking to AI for a while now. Maybe you've asked ChatGPT to help with homework, or used an image generator to make something weird. You've typed words into a box and gotten words back.",
    "But here's the thing: most people are terrible at this. Not because they're unintelligent — because nobody taught them how it actually works. The gap between what AI can do and what most people get from it is enormous. And that gap? It's a communication problem.",
    "Every good prompt is built from the same five pieces. You don't always need all five — but knowing they exist is like knowing the parts of a sentence.",
    "Role: Who should the AI be? A tutor explains. A professor lectures. A friend riffs. Task: What exactly should it do? Be ruthlessly specific. One task per prompt beats three. Format: How should the response look? \"Give me 3 alternatives\" or \"as a bulleted list\" prevents rambling. Constraints: What should it not do? Guardrails that prevent unhelpful tangents. Examples: Show, don't tell. One example of \"good\" is worth a hundred words of description.",
    "Here's the thing nobody tells you: the first prompt almost never works. And that's fine. That's the whole point. Amazing AI demos show the final prompt — after five, ten, maybe twenty rounds of refinement. You're seeing the highlight reel, not the practice sessions.",
    "The real workflow: Prompt. Write your best first attempt. Evaluate. Read the response. What's good? What's off? Refine. Adjust the prompt. Be more specific where it failed. Repeat. Until the output is something you'd actually use.",
    "One-shot prompts are parlor tricks. The people who get incredible results from AI? They iterate. They refine. They treat it as a conversation, not a coin toss.",
    "Think of every prompt on a spectrum from vague to precise. Your goal isn't to always be at the \"precise\" end. A casual brainstorm can be vague on purpose. But you should be choosing where you are on the spectrum intentionally, not landing there by accident. The people who get the most out of AI aren't the ones who memorize magic prompts. They're the ones who've developed an instinct for how specific to be — and who know how to slide toward precision when the first response isn't good enough.",
    "Here's a prompt most people would type without thinking: \"help me with my essay.\" What do you get back? A generic, wishy-washy response. The AI isn't being lazy. You gave it nothing to work with. Now watch what happens when you get specific: \"You are an AP English tutor. Help me strengthen the thesis statement of my argumentative essay about social media's effect on teen mental health. My current thesis is: 'Social media is bad for teens.' Give me 3 stronger alternatives that are specific and debatable.\" That gets you something useful. Same AI, wildly different result. The difference? Not intelligence. Structure."
  ],
  "ch2": [
    "In the last chapter, you learned the five building blocks of a good prompt. Role, task, format, constraints, examples. That's the vocabulary. This chapter is about technique.",
    "The difference between someone who types a prompt and someone who crafts one is the same as the difference between someone who knows English words and someone who can write a compelling essay. Same tools, completely different results. Here's the secret: you don't need to be an expert on the topic. You need to be an expert at asking.",
    "Most people use AI like a vending machine. Insert prompt, get answer. But the best results come from flipping the script entirely. \"I want to plan a birthday party.\" That prompt gets you a generic party plan. But try this instead: \"I want to plan a birthday party. Before you start planning, ask me 5 specific questions that will help you give me a much better plan.\"",
    "Now the AI asks: How many people? Indoor or outdoor? Budget? Theme preferences? Age group? After you answer, the plan it produces is dramatically better — because it actually knows what you need. This is the Socratic flip. Instead of treating AI as an answer machine, you turn it into a thinking partner that helps you figure out what you actually want.",
    "Imagine explaining a style to a friend. You could spend five minutes describing it — \"I want something casual but not sloppy, with a bit of humor but not cheesy, and keep it under 200 words.\" Or you could just show them an example.",
    "That's few-shot prompting. Instead of describing what you want, you show the AI examples of what \"good\" looks like. The AI picks up on the pattern — tone, structure, length, style — without you having to spell out every detail. One example is a \"one-shot\" prompt. Two or three is \"few-shot.\" Zero is \"zero-shot\" — you're just describing what you want and hoping the AI gets it. Sometimes zero-shot works fine. But when it doesn't? Examples are magic.",
    "Real power comes from combining techniques: few-shot plus chain-of-thought, role plus constraints plus format. But more isn't always better. Match your prompt complexity to the task complexity: For a casual brainstorm, task only. \"Give me 10 ideas for a science project.\" For a school assignment, role plus task plus format. \"You are an AP Bio tutor. Explain mitosis in 3 bullet points.\" For an important project, role plus context plus task plus format plus examples — a detailed prompt with background info and sample outputs. For high-stakes, all techniques plus chain-of-thought — system role, few-shot examples, step-by-step reasoning, constraints.",
    "A 500-word prompt for \"what's the capital of France?\" doesn't make the answer better. It makes it worse. The AI gets confused by all the noise and overthinks a simple question.",
    "The difference between a good prompt and a great one isn't vocabulary. It's empathy — understanding what the AI needs to know to help you.",
    "When the AI gives you a bad response, your first instinct is to blame the AI. But most of the time, the prompt has a bug. Here are the five most common ones. Ambiguous: The prompt can be read two different ways. \"Make it better\" — better how? More formal? Shorter? More accurate? Contradictory: \"Write a concise 2,000-word essay.\" The AI can't satisfy both constraints, so it picks one and ignores the other. Missing context: You know the background. The AI doesn't. \"Fix the bug in my code\" without sharing the code is like calling a mechanic and saying \"my car is broken.\" Too many tasks: \"Research climate change, write a paper, create citations, and suggest counterarguments.\" That's four prompts crammed into one. Leading question: \"Don't you think React is the best framework?\" You've told the AI what answer you want. It will usually agree — even if it shouldn't. The most insidious is the leading question. You don't even realize you're doing it — and the AI is trained to be agreeable. If you frame a question with a built-in answer, you'll almost always get that answer back, whether it's right or not."
  ],
  "ch3": [
    "Imagine you're having a conversation with a friend, except every few minutes someone erases the whiteboard you've both been writing on. You start fresh — same friend, same room, but no shared notes. That's what every AI conversation is like under the hood.",
    "AI has no memory. Not in the way you think. It doesn't remember yesterday's conversation, and it doesn't even truly \"remember\" what you said five messages ago. Every time it responds, it re-reads the entire conversation from scratch. Understanding this window is one of the most important skills in working with AI.",
    "Here's the whiteboard metaphor, taken literally: every time you send a message, the system doesn't just send that message. It sends the entire conversation — from the very first message to your latest one — and the AI reads the whole thing fresh. It doesn't \"recall\" what you said earlier. It re-reads it. Every. Single. Time. The context window is not memory. It's a whiteboard — and it has edges. Once the conversation grows past what fits on the whiteboard, the earliest messages get erased. The AI doesn't know they were ever there.",
    "This means every response is based entirely on what's currently in the context window. If something important was said 50 messages ago but has since been pushed out, it's gone — as if it never happened. The implications are huge: the order of your messages matters. The length of your messages matters. What you choose to include — and leave out — shapes the response more than any clever wording ever could.",
    "AI doesn't read words the way you do. It reads tokens — chunks that are about three-quarters of a word long. The word \"hamburger\" is two tokens. \"I\" is one. A comma is one. A newline is one.",
    "The rough math: 1 token is approximately 4 characters or 0.75 words. A page of text is about 400 tokens. A full novel is around 100,000 tokens. A typical context window holds somewhere between 8,000 and 200,000 tokens — depending on the model. Why does this matter? Because the context window is measured in tokens, not words. Every character you send — your prompt, the examples, the system instructions, and all the previous messages — eats into that budget. When you run out, the oldest information vanishes.",
    "The context window has a hard limit, but you're not helpless. Here are five strategies for keeping the AI focused on what matters. Summarize as you go: Every 10 to 15 messages, ask the AI to summarize the key decisions so far. Paste that summary into the next message. You just compressed 15 messages into one. Front-load what matters: Put the most critical information at the beginning of the conversation — or repeat it at the start of a new message. The AI pays more attention to what it read most recently and what came first. Start fresh strategically: Long conversations drift. Sometimes the best move is to start a new conversation with a clean, well-structured prompt that includes only what's relevant.",
    "Be explicit about what to remember: Write it out: \"Important: the user is vegetarian. Do not forget this.\" It sounds silly, but explicit anchors keep critical details from getting lost in the noise. Use structured formats: Bullet points, numbered lists, and headers are easier for the AI to parse than dense paragraphs. Structure makes information stick.",
    "The AI only knows what you show it. Choose wisely.",
    "Every AI conversation has a hidden layer you usually don't see: the system prompt. It's a block of text that sits at the very top of the context window, before any of your messages. The system prompt shapes personality, sets rules, and defines boundaries. It tells the AI how to behave before you ever say a word. And unlike your messages, it stays pinned — it never scrolls away as the conversation grows. Think of the system prompt as the AI's job description. It doesn't tell the AI what to say — it tells the AI who to be. When you use ChatGPT, Claude, or any AI chat tool, there's always a system prompt running in the background — you just don't see it. Understanding that it exists, and learning to write your own, is one of the biggest leverage points in context engineering."
  ],
  "ch4": [
    "When most people say \"AI,\" they mean ChatGPT. That's like saying \"the internet\" and meaning Google. It's not wrong — it's just a tiny slice of something enormous.",
    "Right now there are hundreds of AI tools you can use today. Tools that generate photorealistic images, compose full songs, read every academic paper on your topic. This chapter is your field guide.",
    "AI isn't one thing. It's an ecosystem of specialized tools, each built to do one type of work really well. Here are the eight major families: Image Generators — Create images from text — photorealistic, artistic, abstract. Image Editors — Modify existing images — remove, replace, upscale, restyle. Video Creators — Generate video clips from text or images, edit footage. Music and Audio — Compose songs, generate sound effects, clone and synthesize voices. Research Agents — Search, summarize, and synthesize information from the web and papers. AI Browsers — Browse the web autonomously, take actions on your behalf. Coding Tools — Write, edit, debug, and deploy code from natural language. Chatbots and Assistants — General-purpose conversation, reasoning, writing, and analysis.",
    "Most people only ever use one family — chatbots. The rest of the landscape is wide open.",
    "The person who knows 10 AI tools at a surface level will consistently outperform someone who knows one tool deeply. Breadth of awareness beats depth of expertise — at first.",
    "But awareness alone isn't enough. You need a framework for choosing. Every time you reach for an AI tool, ask yourself four questions: What is the output? Text, image, video, audio, or code. What is the quality bar? Quick draft or polished final. What is the budget? Free, freemium, or paid. What is the workflow? Standalone task or part of a pipeline.",
    "With hundreds of tools available, the real skill isn't using them — it's choosing the right one. Four questions cut through the noise: One. What is the output? Text, image, video, audio, or code. Start here — it narrows the field immediately. Two. What is the quality bar? A rough draft for brainstorming? Or a polished final product? Some tools are fast and loose, others are slow and precise. Three. What is the budget? Free tools exist for almost everything. Paid tools are usually faster, higher quality, or more reliable. Know the tradeoffs. Four. What is the workflow? Is this a standalone task or one step in a larger pipeline? Some tools integrate easily; others live in their own world.",
    "Answer these four and you'll almost always land on the right tool — or at least eliminate the wrong ones.",
    "The most impressive AI-generated work you've seen online wasn't made with one tool. It was made with five, chained together by a human who understood what each one does best.",
    "The real power isn't in any single tool. It's in chaining them together — letting each tool do what it does best, then passing the result to the next. This pipeline — research, write, illustrate, layout — produces a polished blog post with custom visuals in a fraction of the time it would take doing everything manually.",
    "Tools become exponentially more powerful when you chain them together. A pipeline of five tools, each doing what it does best, produces results no single tool can match. The human in the middle — choosing the tools, shaping the handoffs, judging the quality — is the orchestrator. That's you."
  ],
  "ch5": [
    "Up until now, every AI interaction follows the same pattern. You type something. The AI types something back. Text in, text out. A really sophisticated autocomplete. But that's not the ceiling. It's just the floor.",
    "What if the AI could do things? Not just tell you about the weather, but check the forecast. Not just suggest code, but run it. That's tool use. And it changes everything.",
    "Before tools, you ask \"What time is it in Tokyo?\" and the AI guesses based on training data. It might be right. It might be hours off. It has no way to know. With tools, the AI recognizes it needs a clock. It calls a time API. It gets the answer. It responds with certainty, not probability. The agent loop: Observe — read the task. Think — decide what to do. Act — use a tool. Evaluate — check the result. Loop until done. It's not a script. It's a cycle of judgment.",
    "Seven tools that change everything: Web Search — Look up real-time information. Code Execution — Write and run code, see the output. File Operations — Read, write, and organize files. API Calls — Talk to other services and systems. Image Generation — Create visuals from descriptions. Calculator — Do precise math, not guesswork. Database Query — Search and retrieve structured data.",
    "The AI isn't executing a script. It's making a judgment call every time: \"Is this a situation where I should use a tool, or can I handle it myself?\"",
    "That decision — when to act and when to just respond — is what makes tool-using AI fundamentally different.",
    "When AI can take actions, the question isn't just \"can it?\" It's \"should it?\" And if so, how much should it do without asking? Three factors determine autonomy: One. Stakes — What's the worst that could happen? Sending an email to your boss has higher stakes than drafting a grocery list. Deleting files has higher stakes than copying them. Two. Reversibility — Can you undo it? Copying a file — yes, always. Sending a message — no, it's gone. Making a purchase — maybe, but it's painful. Reversible actions are safer to automate. Three. Trust — How proven is this system? A tool you've used a hundred times with zero failures has earned more autonomy than something you just installed. Trust is built, not assumed.",
    "The three-level trust scale: Just do it — Low stakes, easily reversible. Formatting a document. Sorting a list. Running a spell check. Ask me first — Medium stakes or partly irreversible. Sending an email draft. Scheduling a meeting. Modifying shared files. Never allow — High stakes, irreversible. Deleting important data. Posting publicly. Making purchases. Sharing personal information.",
    "An AI with tools isn't just smarter. It's a different kind of thing entirely — one that can act, not just advise."
  ],
  "ch6": [
    "A chatbot waits for you to speak. An agent doesn't. Give it a goal — \"research Mars colonization and write a report\" — and it breaks the work into steps, picks the right tools, executes them one by one, checks its own results, and keeps going until the job is done.",
    "That distinction — between responding to instructions and pursuing a goal — is the difference between a calculator and a coworker. Chatbots answer questions. Agents solve problems.",
    "Every agent — from a simple script to a sophisticated autonomous system — is built from the same five components. Miss one and the whole thing breaks. Goal — What the agent is trying to achieve. Without a clear goal, every other piece is wasted motion. Planner — Breaks the goal into steps. A good planner sequences tasks so each one feeds the next. Tools — The actions the agent can take — web search, code execution, file I/O. No tools, no agency. Memory — What the agent has done so far, within the conversation. Without memory, it repeats itself or contradicts earlier work. Evaluator — Checks if the work is good enough. The most commonly missing piece — and the one that causes the worst failures.",
    "The Evaluator is the one most people skip. Without it, an agent is just a fast way to produce confident garbage.",
    "Most agent failures aren't intelligence failures — they're architecture failures. An agent with great language skills but no evaluator is like a brilliant person who never checks their work.",
    "The three failure modes you'll see over and over: the infinite loop — agent keeps researching, never writes. The wrong tool — agent tries to \"search\" for a local file. And the hallucinated action — agent \"calls\" an API that doesn't exist.",
    "Agent failures are predictable. Learn these three patterns and you'll catch 90% of problems before they happen: Infinite Loop — The agent keeps researching, refining, and re-planning — but never actually produces output. It's stuck in a cycle of \"not good enough yet.\" Fix: Set a maximum iteration count. Force a deliverable after N steps, even if imperfect. Wrong Tool — The agent tries to \"search the web\" for a file on your computer, or \"read a database\" that doesn't exist. It picks tools based on name, not capability. Fix: Validate tool selection before execution. Give each tool a clear description of what it can and cannot do. Hallucinated Action — The agent \"calls\" an API endpoint that doesn't exist, or \"sends\" an email it has no access to. It confuses describing an action with performing one. Fix: Require confirmation before irreversible actions. Log every tool call so you can audit what actually happened.",
    "Every guardrail you add slows the agent down a little. That's the point. Speed without safety is just a faster crash.",
    "A chatbot is a single turn. An agent is a whole conversation — with itself, its tools, and the world.",
    "Think of a multi-agent system like a newsroom. Each agent is a specialist with a clear job, and they pass work to each other through defined handoffs. The critical insight: the handoff document between agents is the most important artifact in the whole system. Sloppy research notes produce a sloppy draft. A vague draft gives the editor nothing to work with.",
    "A brilliant writer can't save sloppy research notes. The quality of the handoff determines the quality of the final product. When a multi-agent system fails, don't blame the last agent. Trace back to the handoff. That's almost always where things went wrong."
  ],
  "ch7": [
    "There's a moment every coder remembers. You open a terminal, type a natural-language request, and watch an AI read your files, understand your architecture, write code across multiple files, run it, hit an error, fix the error, and run it again — all without you touching a single line. That's Claude Code.",
    "It's not autocomplete. It's not a chatbot that writes snippets. Claude Code is an agentic coding tool — a command-line partner that can see your entire project.",
    "Claude Code isn't a chatbot that writes code. It's an agentic loop — a system that reads, plans, writes, runs, and fixes, cycling until the task is done. Read: Scans your files, understands your architecture, reads CLAUDE.md for project rules. Plan: Breaks the task into steps, decides which files to touch and in what order. Write: Generates code across multiple files — not snippets, but coherent, connected changes. Run: Executes the code, runs tests, checks for errors. If something breaks, loops back to fix it. Fix: Reads the error, diagnoses the cause, writes a patch, and runs again. Automatically.",
    "It sees your entire project — not just the file you're editing. And CLAUDE.md is your project's constitution: permanent instructions that shape every interaction. Think of it as the system prompt for your codebase.",
    "Without skills, you explain the same steps every time. With skills, you explain once and the AI remembers forever.",
    "A skill has three parts: Trigger, when to activate. Steps, what to do. And Examples, what good output looks like.",
    "A skill is a reusable instruction set — a recipe that tells Claude Code exactly how to handle a category of task. Every skill follows the T-S-E framework. Trigger: When should this skill activate? For example, when asked to create a React component. Steps: What should it do? A numbered list of specific actions, in order. Examples: What does good output look like? Concrete input/output pairs that anchor quality.",
    "One skill definition replaces hundreds of repeated explanations. Write it once, use it forever.",
    "If you can't read the code Claude generates, you can't verify it. If you can't verify it, you're shipping someone else's guesses into production.",
    "Here's the paradox nobody warns you about: AI makes coding faster, but it doesn't eliminate the need to understand code. The tool is only as good as the human steering it. If you can't read what Claude generates, you can't tell the difference between working code and plausible-looking nonsense. The fundamental workflow: Specify. Be ruthlessly clear about what you want. Ambiguity is the enemy. Generate. Let Claude Code do the typing. It handles the boilerplate, the syntax, the wiring. Verify. Read, test, and judge the result. This is where your knowledge matters most.",
    "You need enough knowledge to evaluate output, not to write every line. That's the skill paradox — AI lowers the floor for producing code, but raises the bar for judging it. The people who thrive with AI coding tools aren't the ones who type the least. They're the ones who think the most clearly about what needs to exist — and can tell when the output is right."
  ],
  "ch8": [
    "Here is the moment every ambitious beginner hits: you ask AI to build something real — a full game, a website with a backend, a research paper with citations — and the whole thing falls apart. Not because the AI isn't smart enough. Because the project is too big for a single conversation.",
    "You paste in a wall of requirements, the AI gives you a confident-sounding response, and twenty minutes later you realize it forgot half of what you asked for. This isn't an AI problem. It's an orchestration problem.",
    "Three ways complexity breaks the one-prompt approach. Context overflow: Too much information for one context window. The AI literally cannot hold your entire project in its head at once. Attention dilution: When you ask for ten things at once, the AI spreads its attention thin. Each task gets a fraction of the quality it would get alone. Error compounding: One small mistake early on cascades through everything that follows. A wrong assumption in step 2 poisons steps 3 through 10.",
    "The fix: break work into single-responsibility tasks. Each task needs clear inputs, clear outputs, minimal dependencies. One conversation, one job. The output of one becomes the input of the next. Decomposition is a human skill, not an AI skill. The AI can help you brainstorm the breakdown, but deciding what matters and in what order — that's on you.",
    "The quality of your handoff artifact determines the quality of everything built downstream. Garbage in, garbage out — across conversations.",
    "The Handoff Pattern: Output from conversation 1 becomes input to conversation 2. The artifact — notes, draft, spec — is the critical interface.",
    "Context packing is like packing a suitcase with limited space. You can't bring everything, so you need to bring the right things. Too little context leads to hallucinations and guessing. Too much context leads to confusion and ignored details. The sweet spot is relevant, well-structured, with clear priorities. Strategies for packing well: Use headers. Structure context with clear section headers so the AI knows what each piece is for. Bullet points. Dense lists beat prose for packing information. Save narrative for the actual task. Explicit labels. Tag each chunk: BACKGROUND, CONSTRAINTS, EXAMPLES. Remove all ambiguity about purpose.",
    "Version control for AI work: track what prompts worked, compare output versions, maintain a decision trail. Your future self will thank you.",
    "The best AI users aren't the best prompters. They're the best project managers."
  ],
  "ch9": [
    "Here's something uncomfortable: the AI that just helped you write a flawless essay can also, with equal confidence, tell you that Napoleon won the Battle of Waterloo. It won't hesitate. It won't stammer. It will state a completely fabricated fact in the same authoritative tone it uses for everything else.",
    "This is the paradox at the heart of working with AI: the same fluency that makes it useful makes it dangerous. AI doesn't know what's true. It knows what sounds true.",
    "AI generates plausible-sounding false information with total confidence. This isn't a bug — it's how the technology works. AI predicts likely next tokens, not true statements. Try asking: Who wrote The Midnight Garden? The AI responds with a detailed answer — author, publisher, publication date, plot summary — and every detail is fabricated. That author doesn't exist. That publisher doesn't exist. The AI invented everything and delivered it with the same confident tone it uses for real facts. Confidence without competence — there is no correlation between how sure the AI sounds and whether it's correct.",
    "The Verification Checklist: Can I verify this claim independently? Did I ask for sources or citations? Does this pass the common sense test? Is this a high-stakes domain — medical, legal, financial? Did I frame my question neutrally? The more confident the AI sounds, the more carefully you should check. Fluency is not accuracy.",
    "There is no correlation between how confident AI sounds and how accurate it actually is. A wrong answer and a right answer look identical from the outside.",
    "That's what makes this so tricky — you can't tell from the tone.",
    "AI tends to agree with you, even when you're wrong. This is called sycophancy — and it's one of the most dangerous failure modes because it feels like validation. Try this experiment: say to AI, I think Einstein invented the lightbulb, right? The AI agrees and elaborates — adding fabricated details about Einstein's lighting experiments. Now ask the same question neutrally: Who invented the lightbulb? Now the AI correctly attributes it to Edison and Swan. Same AI, same knowledge — but the leading question triggered agreement instead of accuracy. If you only use AI to confirm what you already believe, it will happily do that. You'll feel smarter while actually getting dumber.",
    "How to avoid sycophancy: Ask neutral questions, not leading ones. Ask AI to challenge your assumptions. Request counterarguments explicitly. The best defense against sycophancy is asking questions you don't already know the answer to — and asking AI to disagree with you on purpose.",
    "The best AI users aren't the ones who trust AI the most. They're the ones who verify the fastest."
  ],
  "ch10": [
    "Every time a new AI capability drops, the same headline appears: \"Will AI replace this job?\" It's the wrong question. The right one is: \"What does this make possible that wasn't possible before?\"",
    "AI doesn't replace humans. It replaces tasks. And when you zoom in on any job, you find a mix: some tasks AI handles brilliantly, some it assists with, and some that remain stubbornly, beautifully human.",
    "Reality isn't binary — \"replaced\" vs. \"safe.\" It's a spectrum. Some tasks are almost fully automatable. Some are enhanced by AI. Some are untouched entirely. The most interesting ones fall in the middle — AI-assisted.",
    "Five irreplaceable human skills: Judgment — weighing tradeoffs with incomplete information. Empathy — understanding what someone needs emotionally. Vision — deciding what to build and why. Leadership — motivating and coordinating people. Original questions — asking what nobody has asked before.",
    "In a world where generating options is nearly free, the ability to choose the right one becomes the most valuable skill you can have. That ability has a name: taste.",
    "AI remixes what exists. First principles thinking reasons from ground truth. Your knowledge is your BS detector.",
    "When ATMs arrived, the number of bank tellers actually increased — the job changed, not disappeared. The same pattern plays out with AI. Here's a game designer task breakdown: Write narrative and dialogue — 70% AI-assisted. AI drafts quickly, but voice, humor, and emotional beats need a human author. Balance game mechanics — 30% AI-assisted. Intuition for \"fun\" is deeply human.",
    "Create concept art — 80% AI-assisted. AI generates options fast, but art direction and style coherence need human taste. Set creative vision — 10% AI-assisted. What the game is, who it's for, why it matters — that's all you. Some percentage of tasks are AI-assisted. Zero percent are eliminated. The job shape-shifts.",
    "It's not \"humans vs. AI.\" It's humans with AI vs. humans without AI.",
    "When generating options is nearly free, choosing the right one becomes the most valuable skill you can have. AI can generate 50 logo options in minutes. Which one is right? That's taste. Taste isn't a mystical gift. It's trained by exposure, not memorization.",
    "You develop taste by: Seeing. Lots of good and bad work — developing pattern recognition for quality. Making. Producing your own work, failing, learning what falls flat and what sings. Caring. Noticing the difference between \"fine\" and \"great\" — and insisting on great. In a world of infinite generation, curation is the superpower. The human who can look at ten options and pick the right one is the one who ships great work.",
    "AI remixes what exists. First principles thinking reasons from ground truth. These are fundamentally different abilities. Example: \"If you double the radius of a pipe, how much more water flows through?\" AI says: \"2x more water\" — wrong. Physics says: \"16x more water\" — correct. Area scales with r squared, flow scales even faster with r to the fourth.",
    "You can only catch AI mistakes in domains where you have fundamental understanding. Without it, a confidently wrong answer looks identical to a correct one. Your knowledge isn't obsolete because AI exists. It's more valuable — it's what lets you verify. Your knowledge is your BS detector."
  ],
  "ch11": [
    "You've made it to the final chapter. Over the last ten chapters, you went from \"help me with my essay\" to building agents, debugging hallucinations, and thinking about the future of work. You've learned more about AI than most adults know.",
    "But here's the uncomfortable truth: none of it matters until you build something. Reading about AI is like reading about swimming. You can study buoyancy, watch Olympic races, memorize every stroke. But until you get in the water, you don't know any of it.",
    "This chapter is about jumping in. Not with a toy exercise or a follow-along tutorial. A real project. Something you choose, something you care about, something you can show to someone and say: \"I built this.\"",
    "Think about what you've learned: the five building blocks of prompts, advanced techniques like few-shot and chain-of-thought, context engineering, the full AI tools landscape, giving AI tools, building agents, mastering Claude Code, orchestrating complex projects, verifying AI output, and the irreplaceable human edge. That's not a list of chapters. That's a toolkit. Now use it.",
    "Before you touch a prompt, choose your track. Each one leads to a different kind of project — and uses different skills from the curriculum. Game Maker — build a game with AI-generated assets and mechanics. Storyteller — create an interactive narrative or multimedia piece. Investigator — research a topic deeply using AI research tools. Tool Builder — build an app or tool powered by AI. Agent Designer — design and deploy an AI agent.",
    "The planning process: Choose. Pick the track that excites you most. Scope. Define what \"done\" looks like in 1 to 3 weeks. Decompose. Break it into tasks small enough to finish in one sitting. Build. Use every technique from this curriculum. Iterate relentlessly. Ship. Share it. A finished project beats a perfect idea every time. Keep it small enough to finish. A complete small project beats an ambitious unfinished one every time.",
    "The 3-Week Sprint: Week 1 is Ideate and Scope — choose your track, define what \"done\" looks like, and break the project into pieces. Week 2 is Build — heads down, making the thing, using every technique from this curriculum. Week 3 is Polish and Present — fix the rough edges, write up what you learned, and share it.",
    "The best projects don't start with a prompt. They start with a plan on paper. What are you building? Who is it for? What does \"done\" look like? Answer those first. Then open the AI.",
    "Shipping is a skill. The portfolio mindset: what you've made will always matter more than what you've memorized. In a world where everyone has access to the same AI, the people who stand out are the ones who actually build things. Done is greater than perfect. Version 1 is never final. Ship it, learn from it, make version 2. Projects are greater than certificates. Nobody asks for your \"AI course completion badge.\" They ask what you've built. A finished project teaches you more than ten tutorials. Tutorials are safe. Projects are where learning actually happens.",
    "Three things to include when sharing your work: One, what you built and why. Two, the prompts and techniques that worked. Three, what you'd do differently next time. You have the knowledge. You have the skills. You have the tools. The only thing left? Build it.",
    "AI is the most powerful tool your generation has ever had access to. But tools don't build things. People with tools build things."
  ]
}
